{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "Ohy-uGrhk_6j"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import math\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score,f1_score,ConfusionMatrixDisplay\n",
        "import seaborn as sns\n",
        "import random\n",
        "from shapely.geometry import Point, MultiPoint\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import colorsys\n",
        "from skimage.segmentation import slic\n",
        "from skimage.data import astronaut\n",
        "from skimage.color import label2rgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import cv2 as cv\n",
        "from google.colab.patches import cv2_imshow\n",
        "import random\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "5C72evWemRM_"
      },
      "outputs": [],
      "source": [
        "def load_dataset():\n",
        "  image_pickle_file_path = '/content/drive/MyDrive/project/images.pkl'\n",
        "  label_pickle_file_path = '/content/drive/MyDrive/project/label.pkl'\n",
        "\n",
        "  with open(image_pickle_file_path, 'rb') as file:\n",
        "    images = pickle.load(file)\n",
        "\n",
        "  with open(label_pickle_file_path, 'rb') as file:\n",
        "    labels = pickle.load(file)\n",
        "\n",
        "  images = images.reshape(images.shape[0], -1)\n",
        "\n",
        "  return images, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrpnfTOWoxXY",
        "outputId": "19cbb1fd-1080-4597-f045-b59b5699525e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "WoQeqXudbsdK"
      },
      "outputs": [],
      "source": [
        "def classify(datapoints, labels):\n",
        "  test_size = 0.2\n",
        "  X_train, X_test, y_train, y_test = train_test_split(datapoints, labels, test_size=test_size, random_state=42)\n",
        "\n",
        "  clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "  clf.fit(X_train, y_train)\n",
        "\n",
        "  y_pred = clf.predict(X_test)\n",
        "\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "  return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PegQSxmRnEAU",
        "outputId": "9e89c8d7-0c6b-4337-923f-8cbf4c594740"
      },
      "outputs": [],
      "source": [
        "images, true_labels = load_dataset()\n",
        "images[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "FMkiLP5-qVFK",
        "outputId": "a4af9116-60b1-4668-8b6c-7536e049f7bc"
      },
      "outputs": [],
      "source": [
        "\n",
        "def convertToHSV(image):\n",
        "\n",
        "  pixels = np.array(image)\n",
        "  rgb_image = pixels.reshape((499, 499,3))\n",
        "  r, g, b = rgb_image[:, :, 0], rgb_image[:, :, 1], rgb_image[:, :, 2]\n",
        "  vectorized_rgb_to_hsv = np.vectorize(colorsys.rgb_to_hsv)\n",
        "  hsv_image = vectorized_rgb_to_hsv(r / 255.0, g / 255.0, b / 255.0)\n",
        "  hsv_image = np.transpose(hsv_image, (1, 2, 0))\n",
        "  return hsv_image\n",
        "\n",
        "\n",
        "newimg=convertToHSV(images[33])\n",
        "plt.imshow(newimg, cmap='hsv')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "jVFIHemXDdfu"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def convertToPolar(i,j):\n",
        "    center=249\n",
        "    dx = i - center\n",
        "    dy = j - center\n",
        "    distance = math.sqrt(dx**2 + dy**2)\n",
        "    angle_rad = math.atan2(dy, dx)\n",
        "    angle_degrees = math.degrees(angle_rad)\n",
        "    return distance, angle_degrees"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "7xmH34RG972E"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def create(image):\n",
        "    pixels={}\n",
        "    pixels['info'] = []\n",
        "    pixels['x']=[]\n",
        "    pixels['y']=[]\n",
        "    scaler = MinMaxScaler()\n",
        "\n",
        "    for i in range(image.shape[0]):\n",
        "        for j in range(image.shape[1]):\n",
        "            pixel = image[i, j]\n",
        "            distance, angle = convertToPolar(i, j)\n",
        "            normalized_pixel = [pixel[0], pixel[1], pixel[2] ,distance, angle]\n",
        "            pixels['info'].append(normalized_pixel)\n",
        "            pixels['x'].append(j)\n",
        "            pixels['y'].append(500-i)\n",
        "\n",
        "    pixels['info'] = np.array(pixels['info'])\n",
        "    pixels['info'] = scaler.fit_transform(pixels['info'])*np.array([18,6,6,1,1])\n",
        "    return pixels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "jiPNSnOLHjlK"
      },
      "outputs": [],
      "source": [
        "data = create(newimg)\n",
        "# kmeans = KMeans(n_clusters=4, n_init=10, random_state=42).fit(data['info'])\n",
        "# labels = kmeans.labels_\n",
        "\n",
        "# plt.scatter(data['x'], data['y'], c=labels, cmap='viridis')\n",
        "# plt.title('K-means Clustering')\n",
        "# plt.show()\n",
        "\n",
        "def use_kmeans_cv2(img):\n",
        "  np.random.seed(42)\n",
        "  Z = img.reshape((-1, 3)).astype(np.float32)\n",
        "  criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
        "  K = 4\n",
        "  ret, labelss, center = cv.kmeans(Z, K, None, criteria, 10, cv.KMEANS_RANDOM_CENTERS)\n",
        "  center = np.uint8(center)\n",
        "  res = center[labelss.flatten()]\n",
        "  res2 = res.reshape((499,499,3))\n",
        "  # cv2_imshow(res2)\n",
        "  return  center ,labelss.flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "nTWGwfEO0S2U"
      },
      "outputs": [],
      "source": [
        "def groupByLabel(data,labels):\n",
        "  group={}\n",
        "  for info,x,y,label in zip(data['info'],data['x'],data['y'],labels):\n",
        "    if(label not in group.keys()):\n",
        "\n",
        "      group[label]={}\n",
        "      group[label]['x']=[]\n",
        "      group[label]['y']=[]\n",
        "      group[label]['info']=[]\n",
        "\n",
        "    group[label]['info'].append(info)\n",
        "    group[label]['x'].append(x)\n",
        "    group[label]['y'].append(y)\n",
        "  return group\n",
        "\n",
        "def colorVariance(img,group):\n",
        "  total_variance=0\n",
        "  h_list=[]\n",
        "  s_list=[]\n",
        "  v_list=[]\n",
        "  for x,y in zip(group['x'],group['y']):\n",
        "    color= img[500-y][x]\n",
        "    h_list.append(color[0])\n",
        "    s_list.append(color[1])\n",
        "    v_list.append(color[2])\n",
        "  h_variance = np.var(h_list)\n",
        "  s_variance = np.var(s_list)\n",
        "  v_variance = np.var(v_list)\n",
        "\n",
        "  return h_variance , s_variance , v_variance\n",
        "\n",
        "def colorAverage(img,group):\n",
        "  total_variance=0\n",
        "  h_list=[]\n",
        "  s_list=[]\n",
        "  v_list=[]\n",
        "  for x,y in zip(group['x'],group['y']):\n",
        "    color= img[500-y][x]\n",
        "    h_list.append(color[0])\n",
        "    s_list.append(color[1])\n",
        "    v_list.append(color[2])\n",
        "  h_average = np.average(h_list)\n",
        "  s_average = np.average(s_list)\n",
        "  v_average = np.average(v_list)\n",
        "\n",
        "  return h_average , s_average , v_average"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "IlcebVVbC0ea"
      },
      "outputs": [],
      "source": [
        "def hAverage(img,group):\n",
        "  total_variance=0\n",
        "  h_list=[]\n",
        "  for x,y in zip(group['x'],group['y']):\n",
        "    color= img[500-y][x]\n",
        "    h_list.append(color[0])\n",
        "  h_variance = np.average(h_list)\n",
        "  h_min=np.amin(h_list)\n",
        "  h_max=np.amax(h_list)\n",
        "  return h_variance,h_min,h_max"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "cPEPOQTy_fHj"
      },
      "outputs": [],
      "source": [
        "def pointVariance(group):\n",
        "  dist=[]\n",
        "  ang=[]\n",
        "  for i in group['info']:\n",
        "    dist.append(i[3])\n",
        "    ang.append(i[4])\n",
        "\n",
        "  return np.var(dist),np.var(ang)\n",
        "\n",
        "def pointAverage(group):\n",
        "  dist=[]\n",
        "  ang=[]\n",
        "  for i in group['info']:\n",
        "    dist.append(i[3])\n",
        "    ang.append(i[4])\n",
        "\n",
        "  return np.average(dist),np.average(ang)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "FdCXGZaN07y1"
      },
      "outputs": [],
      "source": [
        "#محیط\n",
        "\n",
        "def calculaterPerimeter(group):\n",
        "  point_coordinates = [Point(x, y) for x,y in zip(group['x'],group['y']) ]\n",
        "  multi_point = MultiPoint(point_coordinates)\n",
        "  convex_hull = multi_point.convex_hull\n",
        "\n",
        "  bounding_box = multi_point.bounds\n",
        "  return convex_hull.length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "Olrmd-aB16Do"
      },
      "outputs": [],
      "source": [
        "\n",
        "def circularity(group):\n",
        "  primeter=calculaterPerimeter(group)\n",
        "  area=len(group['x'])\n",
        "  return 4*np.pi*area/(primeter**2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "wS--NnS2gyUB"
      },
      "outputs": [],
      "source": [
        "def aspect_ratio(group):\n",
        "  ymax=np.amax(group['x'])\n",
        "  ymin=np.amin(group['x'])\n",
        "  xmax=np.amax(group['y'])\n",
        "  xmin=np.amin(group['y'])\n",
        "  ydif=ymax-ymin\n",
        "  xdif=xmax-xmin\n",
        "  return (ydif /xdif)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "Xo573In_9qIG"
      },
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler()\n",
        "# c_list=[]\n",
        "# labels_list=[]\n",
        "c_list=np.load('/content/drive/MyDrive/project/c_list.npy')\n",
        "labels_list=np.load('/content/drive/MyDrive/project/labels_list.npy')\n",
        "def findFeatures(images):\n",
        "  features=[]\n",
        "  vectors=[]\n",
        "  i=0\n",
        "  for image in images:\n",
        "    imgvectors=[]\n",
        "    hsvImg=convertToHSV(image)\n",
        "    data = create(hsvImg)\n",
        "    centers  , labelss =c_list[i] ,labels_list[i]  #use_kmeans_cv2(image)\n",
        "    # c_list.append(centers)\n",
        "    # labels_list.append(labelss)\n",
        "\n",
        "\n",
        "    unique, counts = np.unique(labelss, return_counts=True)\n",
        "\n",
        "    groups=groupByLabel(data,labelss)\n",
        "    for g,c in zip(unique,counts):\n",
        "      groups[g]['size']=c\n",
        "\n",
        "\n",
        "\n",
        "    for v in groups.values():\n",
        "        dist,ang=pointAverage(v)\n",
        "        h_avg,s_avg,v_avg=colorAverage(hsvImg,v)\n",
        "        var_dist,var_ang= pointVariance(v)\n",
        "        h_variance , s_variance , v_variance = colorVariance(hsvImg,v)\n",
        "        vector=[h_avg,s_avg,v_avg,dist,ang,circularity(v),aspect_ratio(v),calculaterPerimeter(v),var_dist,var_ang,h_variance , s_variance , v_variance ]\n",
        "        features.append(vector)\n",
        "\n",
        "    i=i+1\n",
        "    print(f'{int(i)}/{len(images)}')\n",
        "\n",
        "  return features\n",
        "\n",
        "def scale(data,coefficients):\n",
        "  features=scaler.fit_transform(data)*np.array(coefficients)\n",
        "  vectors=features.reshape(-1,4,13)\n",
        "  return features,vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "hK6ZVolM5jxd"
      },
      "outputs": [],
      "source": [
        "def getRandomSamples(count):\n",
        "  random.seed(44)\n",
        "  indexes = random.sample(range(len(images)), count)\n",
        "  random_images = [images[i] for i in indexes]\n",
        "  random_labels = [true_labels[i] for i in indexes]\n",
        "  return random_images,random_labels\n",
        "\n",
        "def getFirstSamples(count):\n",
        "  return images[:count],true_labels[:count]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "RzAHNG0gIu3i"
      },
      "outputs": [],
      "source": [
        "my_array,label_array= getRandomSamples(560);\n",
        "# my_array,label_array= getFirstSamples(100);\n",
        "feature_list=np.load('/content/drive/MyDrive/project/feature_list.npy')\n",
        "# feature_list=findFeatures(my_array)\n",
        "# np.save('/content/drive/MyDrive/project/feature_list',feature_list)\n",
        "# np.save('/content/drive/MyDrive/project/c_list',c_list)\n",
        "# np.save('/content/drive/MyDrive/project/labels_list',labels_list)\n",
        "feat,vect=scale(feature_list,[1]*13)\n",
        "cluster = KMeans(n_clusters=40, n_init=10, random_state=42).fit(np.array(feat))\n",
        "labelsDB = cluster.labels_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "sDSL6XNkWw-I"
      },
      "outputs": [],
      "source": [
        "def groupFeaturesByLabels(data,labels):\n",
        "  group={}\n",
        "  vec_to_group={}\n",
        "  for vec,label in zip(data,labels):\n",
        "    if(label not in group.keys()):\n",
        "      group[label]=[]\n",
        "    group[label].append(vec)\n",
        "    vec_to_group[f'{vec}']=label\n",
        "\n",
        "  return group,vec_to_group\n",
        "gro,vec_to_group=groupFeaturesByLabels(feat,labelsDB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "99atEwoy0Qz3"
      },
      "outputs": [],
      "source": [
        "\n",
        "def meanvect(vect):\n",
        "  list_mean_vect=[]\n",
        "  for i in vect:\n",
        "    mean_vect=np.mean(i,axis=0)\n",
        "    list_mean_vect.append(mean_vect)\n",
        "  return list_mean_vect\n",
        "backup_vect=vect.copy()\n",
        "backup_feat=feat.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFGSd5j2r-pw",
        "outputId": "c40ba7a5-8a3e-473b-ca58-c40f6eaec944"
      },
      "outputs": [],
      "source": [
        "from urllib.request import parse_http_list\n",
        "vect=backup_vect.tolist()\n",
        "vectpop=[]\n",
        "count=0\n",
        "count_list=[]\n",
        "worth_part=[]\n",
        "feat_list=meanvect(vect)\n",
        "acc=classify(feat_list,label_array)\n",
        "clf=RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "best_area=[[0,1,2,3] for i in range(len(my_array))]\n",
        "for k in range(3):\n",
        "  worth_area=[]\n",
        "  delete_index=0\n",
        "  clf.fit(feat_list,label_array)\n",
        "  #for i in reversed(range(len(my_array))):\n",
        "  for i in range(len(my_array)):\n",
        "    list_of_all=[]\n",
        "    worth_part,max_acc = [],0#0,100\n",
        "    img=my_array[i]\n",
        "    print(f\"i={i}, k={k}\")\n",
        "    for j in range(4-k):\n",
        "      copy_vect=vect.copy()\n",
        "      vectpop=copy_vect[i].pop(j)\n",
        "      #feat_list=meanvect(copy_vect)\n",
        "      mean_vect=np.mean([vectpop],axis=0)\n",
        "      pred=clf.predict_proba([mean_vect])[0]\n",
        "      label=label_array[i]\n",
        "      acc=pred[label]\n",
        "      print(f\"Accuracy: {acc* 100:.2f}%\")\n",
        "      #classify(feat_list,label_array)\n",
        "      if (acc >= max_acc):\n",
        "        max_acc =acc\n",
        "        worth_part.append(j)\n",
        "        count=len(worth_part)\n",
        "      copy_vect[i].insert(j,vectpop)\n",
        "    if(count>1):\n",
        "      max_dist=0\n",
        "      for delete in worth_part:\n",
        "        if(vect[i][delete][3] >= max_dist):\n",
        "          max_dist=vect[i][delete][3]\n",
        "          delete_index=delete\n",
        "    else:\n",
        "      delete_index=worth_part[0]\n",
        "    worth_area.append(delete_index)\n",
        "    #worth_area.insert(0,delete_index)\n",
        "  for q in range(len(worth_area)):\n",
        "    vect[q].pop(worth_area[q])\n",
        "    best_area[q].pop(worth_area[q])\n",
        "\n",
        "\n",
        "print(\"----final----\")\n",
        "\n",
        "feat_list=meanvect(vect)\n",
        "acc=classify(feat_list,label_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "VYhiBe_mLisT",
        "outputId": "0767b9c1-5ae0-45aa-d32f-0a53850974ae"
      },
      "outputs": [],
      "source": [
        "index=127\n",
        "test_image=my_array[index].reshape((499,499,3))\n",
        "def get_result(image_index):\n",
        "  center,la=c_list[image_index],labels_list[image_index]#use_kmeans_cv2(test_image)\n",
        "  res = center[la]\n",
        "  res2=res.reshape((499,499,3))\n",
        "  label_re=la.reshape((499,499))\n",
        "  color=center[best_area[image_index][0]]\n",
        "  for i in range(499):\n",
        "    for j in range(499):\n",
        "      if(label_re[i][j] in best_area[image_index]):\n",
        "          res2[i][j]=color\n",
        "      else:\n",
        "        res2[i][j]=np.array([0,0,0])\n",
        "  return res2\n",
        "fig = plt.figure(figsize=(10, 7))\n",
        "columns = 2\n",
        "rows = 2\n",
        "fig.add_subplot(rows, columns, 1)\n",
        "plt.imshow(test_image)\n",
        "plt.title(\"Image\")\n",
        "plt.axis('off')\n",
        "fig.add_subplot(rows, columns, 2)\n",
        "plt.imshow(get_result(index))\n",
        "plt.title(\"result\")\n",
        "plt.axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y91UG7QgGDa0",
        "outputId": "44621aa6-d9a4-4909-9eb3-42c482cc6a1d"
      },
      "outputs": [],
      "source": [
        "def classfiyAndremoveMistakes(datapoints, labels):\n",
        "  test_size = 0.2\n",
        "  X_train, X_test, y_train, y_test = train_test_split(datapoints, labels, test_size=test_size, random_state=42)\n",
        "\n",
        "  clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "  clf.fit(X_train, y_train)\n",
        "\n",
        "  y_pred = clf.predict(X_test)#label\n",
        "  y_pred_prob = clf.predict_proba(X_test)#label & %\n",
        "  mistakes=[]\n",
        "  trues=[]\n",
        "  selected_indexes=[]\n",
        "  for a in X_test:\n",
        "    i=0;\n",
        "    for d in datapoints:\n",
        "      if(np.array_equal(a,d)):\n",
        "         selected_indexes.append(i)\n",
        "         break\n",
        "      i=i+1\n",
        "  imgs=[my_array[i] for i in selected_indexes]\n",
        "  labl=[label_array[i] for i in selected_indexes]\n",
        "  total=len(y_pred)#.shape[0]#len\n",
        "  # print(total)\n",
        "  deleted_count=0;\n",
        "  for i,j,z,h in zip(selected_indexes,labl,y_pred,y_pred_prob):\n",
        "    if j!=z:\n",
        "      mistakes.append((i,h[j]))\n",
        "    else:\n",
        "      trues.append((i,h[j]))\n",
        "\n",
        "  sorted_tuples = sorted(mistakes, key = lambda x: x[1])\n",
        "  mistakess=sorted_tuples[int(0.2*total):]\n",
        "  print(f'deleted:{mistakess}')\n",
        "  datapointse=datapoints.copy()\n",
        "  labelse=labels.copy()\n",
        "  for i in sorted(mistakess,reverse=True):\n",
        "    datapointse.pop(i[0])\n",
        "    labelse.pop(i[0])\n",
        "  return datapointse,labelse,mistakess, trues\n",
        "\n",
        "datapoints,labelss,mistakes,trues=classfiyAndremoveMistakes(feat_list,label_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AtFLfKcGDHSR",
        "outputId": "c35fdc40-5e2a-4db1-ed06-9d18ea853e9d"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(5, 40))\n",
        "columns = 2\n",
        "rows = len(mistakes)\n",
        "i=1\n",
        "for index,acc in mistakes:\n",
        "  img=my_array[index].reshape((499,499,3))\n",
        "  fig.add_subplot(rows, columns, i)\n",
        "  plt.imshow(img)\n",
        "  if i==1:\n",
        "    plt.title(\"Image\")\n",
        "  plt.axis('off')\n",
        "  fig.add_subplot(rows, columns, i+1)\n",
        "  plt.imshow(get_result(index))\n",
        "  if i==1:\n",
        "    plt.title(\"result\")\n",
        "  plt.axis('off')\n",
        "  i=i+2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QkdvyERZII5D",
        "outputId": "17c3c4a8-eaa4-4d8d-9cef-a20c22830fe1"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(5, 30))\n",
        "columns = 2\n",
        "trues_sample=random.sample(trues,10)\n",
        "rows = len(trues_sample)\n",
        "i=1\n",
        "for index,acc in trues_sample:\n",
        "  img=my_array[index].reshape((499,499,3))\n",
        "  fig.add_subplot(rows, columns, i)\n",
        "  plt.imshow(img)\n",
        "  plt.title(\"Image\")\n",
        "  plt.axis('off')\n",
        "  fig.add_subplot(rows, columns, i+1)\n",
        "  plt.imshow(get_result(index))\n",
        "  plt.title(f\"probability:{acc}\")\n",
        "  plt.axis('off')\n",
        "  i=i+2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GXHT9ig6MgXM",
        "outputId": "3714b560-d34d-4b46-f8a8-cd55a64286ae"
      },
      "outputs": [],
      "source": [
        "coefficients=[0]*13\n",
        "plt.figure(figsize=(13, 13))\n",
        "correlation_matrix = np.corrcoef(datapoints, rowvar=False)\n",
        "sns.heatmap(correlation_matrix, annot=True)\n",
        "selected_feats=[]\n",
        "best_acc=0\n",
        "best_feat=[]\n",
        "best_coefficients=0\n",
        "acc_list=[]\n",
        "flag=False\n",
        "for i in range(13):\n",
        "  index_best=0\n",
        "  coef_lists=[]\n",
        "  mean_list=[]\n",
        "  best_score=0\n",
        "  selected_acc=0\n",
        "  for index in range(13):\n",
        "      if (index in selected_feats):\n",
        "          continue\n",
        "      coefficients[index]=1\n",
        "      final_feats=datapoints*np.array(coefficients)\n",
        "      print(f\"selected count: {i} -  checking feature {index} \")\n",
        "      acc=classify(final_feats,labelss)\n",
        "      if(best_acc < acc):\n",
        "        best_acc=acc\n",
        "        best_feat=selected_feats.copy()\n",
        "        best_feat.append(index)\n",
        "        best_coefficients=coefficients.copy()\n",
        "      coefficients[index]=0\n",
        "      max_corr=0\n",
        "      corr=0\n",
        "      for s in selected_feats:\n",
        "          corr=abs(correlation_matrix[index,s])\n",
        "          if ( max_corr > corr):\n",
        "              max_corr=corr\n",
        "      normalized_corr=1-max_corr\n",
        "      score = 2 / ((1 / acc) + (1 / normalized_corr))\n",
        "      if(best_score < score):\n",
        "        best_score=score\n",
        "        index_best=index\n",
        "        selected_acc=acc\n",
        "\n",
        "  acc_list.append(selected_acc)\n",
        "  if(i>1):\n",
        "    diff_acc= selected_acc - acc_list[i-1]\n",
        "    if (diff_acc<0):\n",
        "      if (diff_acc<=-0.03 or flag==True):\n",
        "        break;\n",
        "      else:\n",
        "        flag=True\n",
        "  print(f'feature {index_best} selected \\n')\n",
        "  selected_feats.append(index_best)\n",
        "  coefficients[index_best]=1\n",
        "print(f\"selected_feats {selected_feats}\")\n",
        "print(f\"acc {best_acc*100:.2f}%\")\n",
        "print(f\"best_coefficients{best_coefficients}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "YJMGAaAsZzYN",
        "outputId": "0a2d3bbe-d6b3-40e1-a6bc-8df27987af56"
      },
      "outputs": [],
      "source": [
        "plt.plot(range(1,len(acc_list)+1), acc_list)\n",
        "\n",
        "plt.xlabel('iteration')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVA7TLMUpnt7",
        "outputId": "e5b98d8b-0dc6-48a9-bdd1-cc5e3deaaa38"
      },
      "outputs": [],
      "source": [
        "feature_name=['h_average','s_average','v_average','distance_average','angle_average','circularity','aspect_ratio','perimeter','distance_variance','angle_variance','h_variance ','s_variance ','v_variance']\n",
        "print('Ranking of features:')\n",
        "for i,j in enumerate(selected_feats):\n",
        "  print(f'{i+1}.{feature_name[j]}')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
