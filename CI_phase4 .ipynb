{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlHmbjVlV09X",
        "outputId": "f48fab5d-148d-4c15-e541-d9ac64a34cc5"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OU1PPTL9aOxM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.functional import F\n",
        "from tqdm import trange\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctDkQCNaaRMP",
        "outputId": "1f44ec6e-8f44-414f-9055-32ec2f94563a"
      },
      "outputs": [],
      "source": [
        "temp = torch.ones((10, 2))\n",
        "temp.device\n",
        "use_gpu = True\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() and use_gpu else \"cpu\") # New\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddp-QvWGXGPn",
        "outputId": "650956de-25df-4607-d17e-1aa17ee71151"
      },
      "outputs": [],
      "source": [
        "%cd \"/content/drive/MyDrive/phase4\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "mQ5HZBiFWAQv"
      },
      "outputs": [],
      "source": [
        "from utils import get_oxford_splits\n",
        "from utils import custom_plot_training_stats\n",
        "from utils import plot_conf\n",
        "from utils import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xaoq3ftqWxr0",
        "outputId": "ae1c53c4-85ae-4154-d224-ed15b4ec1dbb"
      },
      "outputs": [],
      "source": [
        "A_train_dl, A_test_dl, B_train_dl, B_test_dl, test_all = get_oxford_splits(batch_size = 128,data_loader_seed=111,\n",
        "pin_memory =True,num_workers= 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "NI140TUQZ6TE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(64, 96, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(96),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(96, 96, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(96),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(96, 96, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(96),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(96, 96, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(96),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.Conv2d(96, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        self.conv5 = nn.Sequential(\n",
        "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.pool4 = nn.MaxPool2d(kernel_size=2)\n",
        "        self.flat= nn.Flatten()\n",
        "        self.fc = nn.Linear(4096, 80)\n",
        "#         t = torch.tensor([[[1, 2],\n",
        "# ...                    [3, 4]],\n",
        "# ...                   [[5, 6],\n",
        "# ...                    [7, 8]]])\n",
        "# >>> torch.flatten(t)\n",
        "# tensor([1, 2, 3, 4, 5, 6, 7, 8])\n",
        "# >>> torch.flatten(t, start_dim=1)\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.pool2(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.pool3(x)\n",
        "        x = self.conv5(x)\n",
        "        x = self.pool4(x)\n",
        "        x = self.flat(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Create an instance of the model\n",
        "model = MyModel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VV5weOUsh4Lf",
        "outputId": "71aaf43b-aa8f-4d32-ff2b-54d92f4f720f"
      },
      "outputs": [],
      "source": [
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "model =MyModel().to(device)\n",
        "summary(model, (3, 64, 64))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9xnG1Md1fKlW"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(model: nn.Module, optim: torch.optim.Optimizer,dataloader: DataLoader, loss_fn):\n",
        "\n",
        "    # utils\n",
        "    num_samples = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    running_corrects = 0\n",
        "    running_loss = 0.0\n",
        "\n",
        "    model.train() #\n",
        "\n",
        "    for batch_indx, (inputs, targets) in enumerate(dataloader):\n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        loss = loss_fn(outputs, targets)\n",
        "\n",
        "        loss.backward() # Compute Gradients\n",
        "        optim.step() # Update parameters\n",
        "        optim.zero_grad() # zero the parameter's gradients\n",
        "\n",
        "        _, preds = torch.max(outputs, dim=1) # Explain, [N]\n",
        "        # print(preds)\n",
        "        running_corrects += torch.sum(preds == targets)\n",
        "        running_loss += loss.item()\n",
        "\n",
        "\n",
        "        # if batch_indx == 0:\n",
        "            # print(outputs.device)\n",
        "\n",
        "    epoch_acc = (running_corrects / num_samples) * 100\n",
        "    epoch_loss = (running_loss / num_batches)\n",
        "\n",
        "    return epoch_acc, epoch_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "wayOUgLGfQVr"
      },
      "outputs": [],
      "source": [
        "def test_model(model: nn.Module,dataloader: DataLoader, loss_fn):\n",
        "\n",
        "    pred_label=[]\n",
        "    target_label=[]\n",
        "    # utils\n",
        "    num_samples = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    running_corrects = 0\n",
        "    running_loss = 0.0\n",
        "\n",
        "    model.eval() # you must call `model.eval()` to set dropout and batch normalization layers to evaluation mode before running inference.\n",
        "    with torch.no_grad(): # explain\n",
        "        # more on torch.no_grad(): https://pytorch.org/tutorials/beginner/basics/autogradqs_tutorial.html#disabling-gradient-tracking\n",
        "\n",
        "        for batch_indx, (inputs, targets) in enumerate(dataloader): # Get a batch of Data\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            outputs = model(inputs) # Forward Pass\n",
        "            loss = loss_fn(outputs, targets) # Compute Loss\n",
        "\n",
        "            # loss.backward() # Compute Gradients\n",
        "            # optim.step() # Update parameters\n",
        "            # optim.zero_grad() # zero the parameter's gradients\n",
        "\n",
        "            _, preds = torch.max(outputs, 1) #\n",
        "            running_corrects += torch.sum(preds == targets)\n",
        "            running_loss += loss.item()\n",
        "            for i,j in zip(preds,targets):\n",
        "              pred_label.append(i.cpu())\n",
        "              target_label.append(j.cpu())\n",
        "              # print(pred_label)\n",
        "\n",
        "\n",
        "            if batch_indx == 0:\n",
        "                print(outputs.device)\n",
        "\n",
        "    test_acc = (running_corrects / num_samples) * 100\n",
        "    test_loss = (running_loss / num_batches)\n",
        "\n",
        "    return test_acc, test_loss,pred_label,target_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZ0OGkz-sHVH"
      },
      "outputs": [],
      "source": [
        "# model = MyModel()\n",
        "# model = model.to(device)\n",
        "\n",
        "# max_test=0\n",
        "# best_loss_train=0\n",
        "# best_loss_test=0\n",
        "# best_train=0\n",
        "# best_batch=0\n",
        "# best_learn=0\n",
        "# test_acc_list=[]\n",
        "# train_acc_list=[]\n",
        "# pred_list=[]\n",
        "# all_of_history=[]\n",
        "# targe_list=[]\n",
        "# acc_history = {}\n",
        "# loss_history = {}\n",
        "\n",
        "# best_model=None\n",
        "# checked=[]\n",
        "# # torch.load('checked')\n",
        "# for jj in [256]:#128 ->72.67(0.001) #165,  (worth)\n",
        "#   model = MyModel()\n",
        "#   model = model.to(device)\n",
        "#   acc_history[f'{jj}']={}\n",
        "#   loss_history[f'{jj}']={}\n",
        "#   A_train_dl, A_test_dl, B_train_dl, B_test_dl, test_all = get_oxford_splits(batch_size = jj,data_loader_seed=111,pin_memory =True,num_workers= 2)\n",
        "#   for ii in [0.0001,0.0005,0.005]:#\n",
        "#     isChecked=False\n",
        "#     for c in checked:\n",
        "#       if(c[0]==ii and c[1]==jj):\n",
        "#         isChecked=True\n",
        "#         break\n",
        "#     if( isChecked==False):\n",
        "#       acc_history[f'{jj}'][f'{ii}']={'test':[], 'train':[]}\n",
        "#       loss_history[f'{jj}'][f'{ii}']={'test':[], 'train':[]}\n",
        "#       print(f\"lr{ii } , batch{jj}\")\n",
        "#       learning_rate=ii\n",
        "#       optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "#       cross_entropy = nn.CrossEntropyLoss()\n",
        "\n",
        "#       for epoch in trange(100):\n",
        "#           train_acc, train_loss = train_one_epoch(model=model, optim=optimizer, dataloader=A_train_dl, loss_fn=cross_entropy)\n",
        "#           test_acc, test_loss ,pred,targe= test_model(model=model, dataloader=A_test_dl, loss_fn=cross_entropy)\n",
        "#           # for i ,j in zip(pred,targe):\n",
        "#           #   pred_list.append(i)\n",
        "#           #   targe_list.append(j)\n",
        "\n",
        "#           acc_history[f'{jj}'][f'{ii}']['train'].append(train_acc)\n",
        "#           acc_history[f'{jj}'][f'{ii}']['test'].append(test_acc)\n",
        "#           loss_history[f'{jj}'][f'{ii}']['train'].append(train_loss)\n",
        "#           loss_history[f'{jj}'][f'{ii}']['test'].append(test_loss)\n",
        "#           if (max_test<test_acc) :\n",
        "#             max_test=test_acc\n",
        "#             best_train=train_acc\n",
        "#             best_loss_test=test_loss\n",
        "#             best_loss_train=train_loss\n",
        "#             best_batch=jj\n",
        "#             best_learn=ii\n",
        "#             best_model=model.state_dict()\n",
        "\n",
        "#           # print(f\",train_acc{train_acc}, test_acc{test_acc}, train_loss{train_loss} ,test_loss{test_loss}\")\n",
        "#       checked.append((ii,jj))\n",
        "#       torch.save(checked,'checked')\n",
        "#       print(f\"train_acc{best_train}, test_acc{max_test}, train_loss{best_loss_train} ,test_loss{best_loss_test}\")\n",
        "#       print(\"---------------------------------------------------------------------------------------------------------------------------------------------\")\n",
        "# torch.save(best_model, \"save_model\")\n",
        "# all_of_history=[acc_history[f\"{best_batch}\"][f\"{best_learn}\"],loss_history[f\"{best_batch}\"][f\"{best_learn}\"],pred_list,targe_list]\n",
        "# torch.save(all_of_history,'history')\n",
        "# print(f\"best_batch: {best_batch} , best_learning rate : {best_learn} , best_acc{max}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQfyZ2hiqeGr",
        "outputId": "4abc455c-a9df-483e-c4f8-0b1c7a7eca35"
      },
      "outputs": [],
      "source": [
        "model = MyModel()\n",
        "model = model.to(device)\n",
        "learning_rate=0.0003\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "cross_entropy = nn.CrossEntropyLoss()\n",
        "\n",
        "test_acc_list=[]\n",
        "train_acc_list=[]\n",
        "pred_list=[]\n",
        "all_of_history=[]\n",
        "targe_list=[]\n",
        "acc_history = {'train': [], 'test': []}\n",
        "loss_history = {'train': [], 'test': []}\n",
        "best_model=None\n",
        "best_test_acc=0\n",
        "for epoch in trange(40):\n",
        "    train_acc, train_loss = train_one_epoch(model=model, optim=optimizer, dataloader=A_train_dl, loss_fn=cross_entropy)\n",
        "    test_acc, test_loss ,pred,targe= test_model(model=model, dataloader=A_test_dl, loss_fn=cross_entropy)\n",
        "    for i ,j in zip(pred,targe):\n",
        "      pred_list.append(i)\n",
        "      targe_list.append(j)\n",
        "\n",
        "    acc_history['train'].append(train_acc)\n",
        "    acc_history['test'].append(test_acc)\n",
        "    loss_history['train'].append(train_loss)\n",
        "    loss_history['test'].append(test_loss)\n",
        "    all_of_history=[acc_history,loss_history,pred_list,targe_list]\n",
        "    torch.save(all_of_history,'history')\n",
        "    if(best_test_acc<test_acc):\n",
        "      best_test_acc=test_acc\n",
        "      best_model=model.state_dict()\n",
        "\n",
        "\n",
        "    print(f\"train_acc{train_acc}, test_acc{test_acc}, train_loss{train_loss} ,test_loss{test_loss}\")\n",
        "\n",
        "torch.save(best_model, \"model3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HU8vkce84THk"
      },
      "outputs": [],
      "source": [
        "# for i,param in model.named_parameters():\n",
        "  # print(f'i{i} ,param{param}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sRRylJ56J24O"
      },
      "outputs": [],
      "source": [
        "\n",
        "8# import torch.nn as nn\n",
        "# import torch.optim as optim\n",
        "# from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "# param_grid = {\n",
        "#     'learning_rate': [0.0001,0.001,0.0005,0.005,0.05, 0.01, 0.1],\n",
        "#     'batch_size':[128,256,200]\n",
        "# }\n",
        "\n",
        "# def train_and_evaluate(learning_rate,batch_size):\n",
        "#     # A_train_dl, A_test_dl, B_train_dl, B_test_dl, test_all = get_oxford_splits(batch_size = 128,data_loader_seed=111,pin_memory =True,num_workers= 2)\n",
        "#     model = MyModel()\n",
        "#     model = model.to(device)\n",
        "\n",
        "#     optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "#     cross_entropy = nn.CrossEntropyLoss()\n",
        "\n",
        "#     # Lists for storing accuracy and loss for each epoch\n",
        "#     acc_history = {'train': [], 'test': []}\n",
        "#     loss_history = {'train': [], 'test': []}\n",
        "\n",
        "#     for epoch in trange(1):\n",
        "#         train_acc, train_loss = train_one_epoch(model=model, optimizer=optimizer, dataloader=A_train_dl, loss_fn=cross_entropy)\n",
        "#         test_acc, test_loss, pred, targe = test_model(model=model, dataloader=A_test_dl, loss_fn=cross_entropy)\n",
        "\n",
        "#         acc_history['train'].append(train_acc)\n",
        "#         acc_history['test'].append(test_acc)\n",
        "#         loss_history['train'].append(train_loss)\n",
        "#         loss_history['test'].append(test_loss)\n",
        "\n",
        "#     return acc_history, loss_history, pred, targe\n",
        "\n",
        "# # Create an instance of GridSearchCV\n",
        "# gs = GridSearchCV(estimator=train_and_evaluate, param_grid=param_grid, cv=3)\n",
        "\n",
        "# # Fit the GridSearchCV instance to perform the grid search\n",
        "# # gs.fit(X=A_train_dl)  # Pass your training data if required\n",
        "\n",
        "# # Print the best hyperparameters and their respective scores\n",
        "# print(\"Best hyperparameters:\", gs.best_params_)\n",
        "# print(\"Best score:\", gs.best_score_)\n",
        "\n",
        "# # Access the results of each parameter combination\n",
        "# print(\"Grid search results:\")\n",
        "# for params, mean_score, _ in gs.cv_results_:\n",
        "#     print(\"Parameters:\", params)\n",
        "#     print(\"Mean score:\", mean_score)\n",
        "\n",
        "# # Save the best model\n",
        "# best_model = gs.best_estimator_\n",
        "# torch.save(best_model.state_dict(), \"save_model2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 982
        },
        "id": "oMaxsxZnz5in",
        "outputId": "b7c54502-82e7-4b47-93c8-d00f4029eee3"
      },
      "outputs": [],
      "source": [
        "acc_history,loss_history,targe_lists, pred_lists=torch.load(\"history\")\n",
        "model.load_state_dict(torch.load(\"model3\"))\n",
        "plot_conf(targe_lists, pred_lists, \"confusion_matrix\",\"plot\", \"matrix_label\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "K5-YMs_HV6aX",
        "outputId": "80cb5f6e-3d90-498b-e4da-5129f1179441"
      },
      "outputs": [],
      "source": [
        "acc_history_cpu = {key: [value.to('cpu').numpy() for value in values] for key, values in acc_history.items()}\n",
        "loss_history_cpu = {key: np.array(values) for key, values in loss_history.items()}\n",
        "\n",
        "\n",
        "custom_plot_training_stats(acc_history_cpu, loss_history_cpu, ['train', 'test'], title='demo', dir='demo_plots')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "lwrsO5qKQZVV"
      },
      "source": [
        "#  section 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "_P3hQoK0uiCe"
      },
      "outputs": [],
      "source": [
        "def train_test(model, epochs, out_path,check_all):\n",
        "    model = model.to(device)\n",
        "    learning_rate = 0.0003\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    # parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "    # optimizer = torch.optim.Adam(parameters, lr=learning_rate)\n",
        "    cross_entropy = nn.CrossEntropyLoss()\n",
        "    all_of_history = []\n",
        "    acc_history = {'train': [], 'test_B': [], 'all': [],'test_A': []}\n",
        "    loss_history = {'train': [], 'test_B': [], 'all': [],'test_A': []}\n",
        "\n",
        "    for epoch in trange(epochs):\n",
        "        pred_list = []\n",
        "        target_list = []\n",
        "        train_acc, train_loss = train_one_epoch(model=model, optim=optimizer, dataloader=B_train_dl, loss_fn=cross_entropy)\n",
        "        test_acc, test_loss, pred, target = test_model(model=model, dataloader=B_test_dl, loss_fn=cross_entropy)\n",
        "        acc_all, loss_all, pred_all, target_all = test_model(model=model, dataloader=test_all, loss_fn=cross_entropy)\n",
        "        acc_a, loss_a, pred_a, target_a = test_model(model=model, dataloader=A_test_dl, loss_fn=cross_entropy)\n",
        "        for i, j in zip(pred_all, target_all):\n",
        "            pred_list.append(i)\n",
        "            target_list.append(j)\n",
        "\n",
        "        acc_history['train'].append(train_acc)\n",
        "        acc_history['test_B'].append(test_acc)\n",
        "        loss_history['train'].append(train_loss)\n",
        "        loss_history['test_B'].append(test_loss)\n",
        "        acc_history['all'].append(acc_all)\n",
        "        loss_history['all'].append(loss_all)\n",
        "        acc_history['test_A'].append(acc_a)\n",
        "        loss_history['test_A'].append(loss_a)\n",
        "        all_of_history = [acc_history, loss_history]\n",
        "        torch.save(all_of_history, f'history{out_path}')\n",
        "        if (check_all ):\n",
        "          plot_conf(target_list, pred_list, \"confusion_matrix\", f'{out_path}/all', f\"conf_matrix_{epoch}\")\n",
        "        if ( check_all==None):\n",
        "          plot_conf(target_list, pred_list, \"confusion_matrix\", f'{out_path}', f\"conf_matrix_{epoch}\")\n",
        "\n",
        "        print(f\"train_acc{train_acc}, test_acc{test_acc}, train_loss{train_loss}, test_loss{test_loss}, all_acc {acc_all}, all_loss {loss_all}\")\n",
        "\n",
        "        acc_history_cpu = {key: [value.to('cpu').numpy() for value in values] for key, values in acc_history.items()}\n",
        "        loss_history_cpu = {key: np.array(values) for key, values in loss_history.items()}\n",
        "        if (check_all):\n",
        "          custom_plot_training_stats(acc_history_cpu, loss_history_cpu, ['train', 'all'], title='plot', dir=f'{out_path}/all')\n",
        "        if (check_all==None):\n",
        "          custom_plot_training_stats(acc_history_cpu, loss_history_cpu, ['train', 'all','test_B', 'test_A'], title='plot', dir=f'{out_path}')\n",
        "\n",
        "        else :\n",
        "          custom_plot_training_stats(acc_history_cpu, loss_history_cpu, ['train', 'test_B', 'test_A'], title='plot', dir=f'{out_path}/B')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wUoUOCoQ3ZXZ"
      },
      "outputs": [],
      "source": [
        "# model2=MyModel()\n",
        "# model2.load_state_dict(torch.load(\"model3\"))\n",
        "# for i,param in model2.named_parameters():\n",
        "#   print(f'i{i} ,param{param}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "9SfdOOqNg5ks"
      },
      "outputs": [],
      "source": [
        "def copy_model():\n",
        "  new_model=MyModel()\n",
        "  new_model.load_state_dict(torch.load(\"model3\"))\n",
        "  in_features = new_model.fc.in_features\n",
        "  last_w_fc= nn.Parameter(new_model.fc.weight[:80].detach().clone(), requires_grad=True)\n",
        "  last_b_fc= nn.Parameter(new_model.fc.bias[:80].detach().clone(), requires_grad=True)\n",
        "\n",
        "  new_model.fc = nn.Linear(in_features, 100)\n",
        "\n",
        "  # Creating new parameters with old and new combined\n",
        "  new_w_fc = nn.Parameter(torch.cat((last_w_fc, new_model.fc.weight[80:])), requires_grad=True)\n",
        "  new_b_fc = nn.Parameter(torch.cat((last_b_fc, new_model.fc.bias[80:])), requires_grad=True)\n",
        "\n",
        "  new_model.fc.weight = new_w_fc\n",
        "  new_model.fc.bias = new_b_fc\n",
        "  return new_model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "kJN8JJ-ARW_p"
      },
      "source": [
        "section 2.1\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Pbn9Xu7HQk5t",
        "outputId": "a58bff81-6f6c-418d-d6df-22855720da32"
      },
      "outputs": [],
      "source": [
        "model2=copy_model()\n",
        "train_test(model2,20,\"2_1\",True)\n",
        "# for i,param in model2.named_parameters():\n",
        "#   print(f'i{i} ,param{param}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nisYh1Scw18_",
        "outputId": "807cb751-5c1f-467f-fdac-d77229a9e425"
      },
      "outputs": [],
      "source": [
        "model2=copy_model()\n",
        "train_test(model2,50,\"2_1\",False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9hrWFydXSn0e"
      },
      "outputs": [],
      "source": [
        "# # add random noise\n",
        "# augmented_dataset = []\n",
        "# original_dataset = B_train_dl\n",
        "\n",
        "# for i in range(10):\n",
        "#   for samples, labels in original_dataset:\n",
        "#     for sample,label in zip(samples, labels):\n",
        "#       noise = torch.randn(sample.shape) * 0.1 # You can adjust the scale factor\n",
        "#       # Add noise to your features\n",
        "#       augmented_sample = sample + noise\n",
        "#       augmented_dataset.append((augmented_sample, label))\n",
        "\n",
        "# # Combine original and augmented datasets\n",
        "# combined_dataset = original_dataset + augmented_dataset\n",
        "\n",
        "# # Create DataLoader for training\n",
        "# batch_size = 128\n",
        "# def seed_worker(worker_id):\n",
        "#         # worker_seed = torch.initial_seed() % 2 ** 32\n",
        "#         np.random.seed(111)\n",
        "#         random.seed(111)\n",
        "# g = torch.Generator()\n",
        "# g.manual_seed(111)\n",
        "# train_loader = torch.utils.data.DataLoader(\n",
        "#         combined_dataset,\n",
        "#         batch_size = batch_size,\n",
        "#         shuffle=True,\n",
        "#         worker_init_fn=seed_worker,\n",
        "#         generator= torch.Generator(),\n",
        "#         drop_last=False,\n",
        "#         pin_memory=True,\n",
        "#         num_workers=2\n",
        "#     )\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ffvkfoakTEF4"
      },
      "source": [
        "section 2.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ogcuZ-hTvqsA",
        "outputId": "7ab5744f-31c0-4ec6-904f-81a177ffd2fe"
      },
      "outputs": [],
      "source": [
        "model3=copy_model()\n",
        "\n",
        "for param in model3.conv1.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "for param in model3.conv2.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "for param in model3.conv3.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "for param in model3.conv4.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "for param in model3.conv5.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "train_test(model3,20,\"2_2\",True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UwZhderrTfHR",
        "outputId": "dbc9e703-d010-40f2-94a2-70dd678ea098"
      },
      "outputs": [],
      "source": [
        "model3=copy_model()\n",
        "\n",
        "for param in model3.conv1.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "for param in model3.conv2.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "for param in model3.conv3.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "for param in model3.conv4.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "for param in model3.conv5.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "train_test(model3,50,\"2_2\",False)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "JE3XaHTnW_Bl"
      },
      "source": [
        "section 2.3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3dKGzzjwmRU4",
        "outputId": "25fd588a-cebd-40ab-973a-cf98539a9bf8"
      },
      "outputs": [],
      "source": [
        "model4 = MyModel()\n",
        "# model4.load_state_dict(torch.load(\"model3\"))\n",
        "\n",
        "in_features = model4.fc.in_features\n",
        "# model4.fc = nn.Linear(in_features, 100)\n",
        "\n",
        "model4=copy_model()\n",
        "\n",
        "for param in model4.conv1.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "for param in model4.conv2.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "for param in model4.conv3.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "for param in model4.conv4.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "for param in model4.conv5.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "mask = torch.cat([torch.zeros(80, in_features), torch.ones(20, in_features)], dim=0).to(device)\n",
        "\n",
        "def masked_backward_hook(grad):\n",
        "    return grad * mask\n",
        "\n",
        "# Apply the mask to the gradients of the last FC layer\n",
        "model4.fc.weight.register_hook(masked_backward_hook)\n",
        "\n",
        "\n",
        "train_test(model4,25, \"2_3\",None)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
