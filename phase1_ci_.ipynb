{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ohy-uGrhk_6j"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5C72evWemRM_"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def load_dataset():\n",
        "  image_pickle_file_path = '/content/drive/MyDrive/project/images.pkl'\n",
        "  label_pickle_file_path = '/content/drive/MyDrive/project/ label.pkl'\n",
        "\n",
        "  with open(image_pickle_file_path, 'rb') as file:\n",
        "    images = pickle.load(file)\n",
        "\n",
        "  with open(label_pickle_file_path, 'rb') as file:\n",
        "    labels = pickle.load(file)\n",
        "\n",
        "  images = images.reshape(images.shape[0], -1)\n",
        "\n",
        "  return images, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrpnfTOWoxXY",
        "outputId": "8451d9a7-3420-4bdc-b73f-0279b6b7c543"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WoQeqXudbsdK"
      },
      "outputs": [],
      "source": [
        "# Classify the datapoints with the Random Forest Classifier\n",
        "\n",
        "def classify(datapoints, labels):\n",
        "  test_size = 0.2\n",
        "  X_train, X_test, y_train, y_test = train_test_split(datapoints, labels, test_size=test_size, random_state=42)\n",
        "\n",
        "  clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "  clf.fit(X_train, y_train)\n",
        "\n",
        "  y_pred = clf.predict(X_test)\n",
        "\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  print(f\"Accuracy: {accuracy * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PegQSxmRnEAU"
      },
      "outputs": [],
      "source": [
        "images, true_labels = load_dataset()\n",
        "images[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FMkiLP5-qVFK"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import colorsys\n",
        "def convertToHSV(image):\n",
        "\n",
        "  pixels = np.array(image)\n",
        "  rgb_image = pixels.reshape((499, 499,3))\n",
        "  r, g, b = rgb_image[:, :, 0], rgb_image[:, :, 1], rgb_image[:, :, 2]\n",
        "  vectorized_rgb_to_hsv = np.vectorize(colorsys.rgb_to_hsv)\n",
        "  hsv_image = vectorized_rgb_to_hsv(r / 255.0, g / 255.0, b / 255.0)\n",
        "  hsv_image = np.transpose(hsv_image, (1, 2, 0))\n",
        "  return hsv_image\n",
        "\n",
        "\n",
        "newimg=convertToHSV(images[33])\n",
        "# original=np.array(images[33]).reshape((499, 499,3))\n",
        "# for i in range(0,10):\n",
        "#   print('rgb:',original[i][0])\n",
        "#   print('hsv',newimg[i][0])\n",
        "#   print(\"--------\")\n",
        "plt.imshow(newimg, cmap='hsv')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I1IevBLBHNW4"
      },
      "outputs": [],
      "source": [
        "\n",
        "# def deleteGreen(image):\n",
        "#     hsv_image = convertToHSV(image)\n",
        "#     h, s, v = hsv_image[:, :, 0], hsv_image[:, :, 1], hsv_image[:, :, 2]\n",
        "#     green_pixels = (h >= 0.3) & (h <= 0.5) #& (s >= 0.3)\n",
        "#     hsv_image[green_pixels, :] = 0\n",
        "#     return hsv_image\n",
        "\n",
        "# newimg=deleteGreen(images[33])\n",
        "# plt.imshow(newimg, cmap='hsv')\n",
        "\n",
        "# plt.axis('off')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QIAQHenjHCU4"
      },
      "outputs": [],
      "source": [
        "# img=images\n",
        "\n",
        "# plt.subplot(1, 3, 1)\n",
        "# plt.imshow(np.array(img).reshape((499, 499,3)))\n",
        "\n",
        "# plt.subplot(1, 3, 2)\n",
        "# newimg=convertToHSV(img)\n",
        "# plt.imshow(newimg, cmap='hsv')\n",
        "\n",
        "# plt.subplot(1, 3, 3)\n",
        "# newimg=deleteGreen(img)\n",
        "# plt.imshow(newimg, cmap='hsv')\n",
        "# plt.axis('off')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVFIHemXDdfu"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "def convertToPolar(i,j):\n",
        "    center=249\n",
        "    dx = i - center\n",
        "    dy = j - center\n",
        "    distance = math.sqrt(dx**2 + dy**2)\n",
        "    angle_rad = math.atan2(dy, dx)\n",
        "    angle_degrees = math.degrees(angle_rad)\n",
        "    return distance, angle_degrees\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xmH34RG972E"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "def create(image):\n",
        "    pixels={}\n",
        "    pixels['info'] = []\n",
        "    pixels['x']=[]\n",
        "    pixels['y']=[]\n",
        "    scaler = MinMaxScaler()\n",
        "\n",
        "    for i in range(image.shape[0]):\n",
        "        for j in range(image.shape[1]):\n",
        "            pixel = image[i, j]\n",
        "            distance, angle = convertToPolar(i, j)\n",
        "            normalized_pixel = [pixel[0], pixel[1], pixel[2] ,distance, angle]\n",
        "            pixels['info'].append(normalized_pixel)\n",
        "            pixels['x'].append(j)\n",
        "            pixels['y'].append(500-i)\n",
        "\n",
        "    pixels['info'] = np.array(pixels['info'])\n",
        "    pixels['info'] = scaler.fit_transform(pixels['info'])*np.array([18,6,6,1,1])\n",
        "    return pixels\n",
        "\n",
        "# normalized_data = create(newimg)\n",
        "# images[33][1][1]\n",
        "# normalized_data['info'][:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jiPNSnOLHjlK"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# wcss = []\n",
        "# data = create(newimg)\n",
        "# for n_clusters in range(1,7):\n",
        "#     kmeans = KMeans(n_clusters=n_clusters, n_init=100)\n",
        "#     kmeans.fit(data['info'])\n",
        "#     wcss.append(kmeans.inertia_)\n",
        "#     print(wcss)\n",
        "\n",
        "\n",
        "# plt.plot(range(1, 7), wcss)\n",
        "# plt.title('Elbow Method')\n",
        "# plt.xlabel('Number of Clusters')\n",
        "# plt.ylabel('WCSS')\n",
        "# plt.show()\n",
        "\n",
        "\n",
        "data = create(newimg)\n",
        "kmeans = KMeans(n_clusters=4, n_init=10, random_state=42).fit(data['info'])\n",
        "labels = kmeans.labels_\n",
        "\n",
        "# pca = PCA(n_components=3)\n",
        "# reduced_data = pca.fit_transform(data)\n",
        "\n",
        "plt.scatter(data['x'], data['y'], c=labels, cmap='viridis')\n",
        "plt.title('K-means Clustering')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nTWGwfEO0S2U"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "#\n",
        "# data = create(newimg)\n",
        "def groupByLabel(data,labels):\n",
        "  group={}\n",
        "  for info,x,y,label in zip(data['info'],data['x'],data['y'],labels):\n",
        "    if(label not in group.keys()):\n",
        "\n",
        "      group[label]={}\n",
        "      group[label]['x']=[]\n",
        "      group[label]['y']=[]\n",
        "      group[label]['info']=[]\n",
        "\n",
        "    group[label]['info'].append(info)\n",
        "    group[label]['x'].append(x)\n",
        "    group[label]['y'].append(y)\n",
        "  return group\n",
        "\n",
        "def colorVariance(img,group):\n",
        "  total_variance=0\n",
        "  h_list=[]\n",
        "  s_list=[]\n",
        "  v_list=[]\n",
        "  for x,y in zip(group['x'],group['y']):\n",
        "    color= img[500-y][x]\n",
        "    h_list.append(color[0])\n",
        "    s_list.append(color[1])\n",
        "    v_list.append(color[2])\n",
        "  h_variance = np.var(h_list)\n",
        "  s_variance = np.var(s_list)\n",
        "  v_variance = np.var(v_list)\n",
        "  # total_variance = h_variance  + s_variance + v_variance\n",
        "\n",
        "  return h_variance , s_variance , v_variance\n",
        "\n",
        "def colorAverage(img,group):\n",
        "  total_variance=0\n",
        "  h_list=[]\n",
        "  s_list=[]\n",
        "  v_list=[]\n",
        "  for x,y in zip(group['x'],group['y']):\n",
        "    color= img[500-y][x]\n",
        "    h_list.append(color[0])\n",
        "    s_list.append(color[1])\n",
        "    v_list.append(color[2])\n",
        "  h_variance = np.average(h_list)\n",
        "  s_variance = np.average(s_list)\n",
        "  v_variance = np.average(v_list)\n",
        "  # total_variance = h_variance  + s_variance + v_variance\n",
        "\n",
        "  return h_variance , s_variance , v_variance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IlcebVVbC0ea"
      },
      "outputs": [],
      "source": [
        "def hAverage(img,group):\n",
        "  total_variance=0\n",
        "  h_list=[]\n",
        "  for x,y in zip(group['x'],group['y']):\n",
        "    color= img[500-y][x]\n",
        "    h_list.append(color[0])\n",
        "  h_variance = np.average(h_list)\n",
        "  h_min=np.amin(h_list)\n",
        "  h_max=np.amax(h_list)\n",
        "  return h_variance,h_min,h_max"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPEPOQTy_fHj"
      },
      "outputs": [],
      "source": [
        "def pointVariance(group):\n",
        "  # print(group['info'][0:3])\n",
        "  three=[]\n",
        "  four=[]\n",
        "  for i in group['info']:\n",
        "    three.append(i[3])\n",
        "    four.append(i[4])\n",
        "  # total_variance=np.var(three)\n",
        "\n",
        "  return np.var(three),np.var(four)\n",
        "\n",
        "def pointAverage(group):\n",
        "  # print(group['info'][0:3])\n",
        "  three=[]\n",
        "  four=[]\n",
        "  for i in group['info']:\n",
        "    three.append(i[3])\n",
        "    four.append(i[4])\n",
        "  # total_variance=np.var(three)\n",
        "\n",
        "  return np.average(three),np.average(four)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FdCXGZaN07y1"
      },
      "outputs": [],
      "source": [
        "#محیط\n",
        "from shapely.geometry import Point, MultiPoint\n",
        "\n",
        "def calculaterPerimeter(group):\n",
        "  point_coordinates = [Point(x, y) for x,y in zip(group['x'],group['y']) ]#zip(test_coordinates['x'],test_coordinates['y'])\n",
        "  multi_point = MultiPoint(point_coordinates)\n",
        "  convex_hull = multi_point.convex_hull\n",
        "\n",
        "  bounding_box = multi_point.bounds\n",
        "  return convex_hull.length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Olrmd-aB16Do"
      },
      "outputs": [],
      "source": [
        "\n",
        "def circularity(group):\n",
        "  primeter=calculaterPerimeter(group)\n",
        "  area=len(group['x'])\n",
        "  return 4*np.pi*area/(primeter**2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhQWJhl40Uki"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WdYSBo1uCPZx"
      },
      "outputs": [],
      "source": [
        "!pip install tqdm\n",
        "from tqdm import tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wS--NnS2gyUB"
      },
      "outputs": [],
      "source": [
        "def aspect_ratio(group):\n",
        "  # for x,y in zip(group['x'],group['y']):\n",
        "  ymax=np.amax(group['x'])\n",
        "  ymin=np.amin(group['x'])\n",
        "  xmax=np.amax(group['y'])\n",
        "  xmin=np.amin(group['y'])\n",
        "  ydif=ymax-ymin\n",
        "  xdif=xmax-xmin\n",
        "  return (ydif /xdif)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xo573In_9qIG"
      },
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler()\n",
        "def findFeatures(images):\n",
        "  features=[]\n",
        "  vectors=[]\n",
        "  i=0\n",
        "  for image in images:\n",
        "    imgvectors=[]\n",
        "    hsvImg=convertToHSV(image)#deleteGreen(image)#\n",
        "    data = create(hsvImg)\n",
        "    kmeans = KMeans(n_clusters=4, n_init=10, random_state=42).fit(data['info'])\n",
        "    labels = kmeans.labels_\n",
        "    centers=kmeans.cluster_centers_\n",
        "    data['centers_x']=centers[:,3]\n",
        "    data['centers_y']=centers[:,4]\n",
        "\n",
        "    unique, counts = np.unique(labels, return_counts=True)\n",
        "    groups=groupByLabel(data,labels)\n",
        "    for g,c in zip(unique,counts):\n",
        "      groups[g]['size']=c\n",
        "\n",
        "      # groups[g]['center_x']=data['centers_x'][g]\n",
        "      # groups[g]['center_y']=data['centers_y'][g]\n",
        "\n",
        "    for v in groups.values():\n",
        "        dist,ang=pointAverage(v)#pointVariance(v)\n",
        "        # hcolor,scolor,vcolor=colorVariance(hsvImg,v)\n",
        "        # h_avg,h_min,h_max=hAverage(hsvImg,v)\n",
        "        h_avg,s_avg,v_avg=colorAverage(hsvImg,v)\n",
        "\n",
        "        vector=[h_avg,s_avg,v_avg,dist,ang,circularity(v)]#hcolor,scolor,vcolor.v['center_x'],v['center_y']\n",
        "        features.append(vector)\n",
        "        #,v['size'],,aspect_ratio(v),h_min,h_max\n",
        "        # imgvectors.append(vector)\n",
        "    # vectors.append(imgvectors)\n",
        "    i=i+1\n",
        "    print(f'{int(i)}/{len(images)}')\n",
        "\n",
        "  return features\n",
        "\n",
        "def scale(data):\n",
        "  features=scaler.fit_transform(data)*np.array([6,4,4,3,3,4])#best:[6,5,4,4,3,3,4]  69.74%\n",
        "  vectors=features.reshape(-1,4,6)\n",
        "  return features,vectors\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WWMt5piCM3t6"
      },
      "outputs": [],
      "source": [
        "# a = np.arange(6).reshape((-1, 2))\n",
        "# a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hK6ZVolM5jxd"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "def getRandomSample(count):\n",
        "  random.seed(44)\n",
        "  indexes = random.sample(range(len(images)), count)\n",
        "  random_images = [images[i] for i in indexes]\n",
        "  random_labels = [true_labels[i] for i in indexes]\n",
        "  return random_images,random_labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RzAHNG0gIu3i"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "# my_array,label_array= getRandomSample(len(images));\n",
        "# feature_list=findFeatures(my_array)\n",
        "feat,vect=scale(feature_list)\n",
        "cluster = KMeans(n_clusters=40, n_init=10, random_state=42).fit(np.array(feat))\n",
        "labelsDB = cluster.labels_\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yte_fMTxIjEs"
      },
      "outputs": [],
      "source": [
        "# # wcss = []\n",
        "# # for n_clusters in range(1,100):\n",
        "# #     kmeans = KMeans(n_clusters=n_clusters, n_init=10)\n",
        "# #     kmeans.fit(np.array(feat))\n",
        "# #     wcss.append(kmeans.inertia_)\n",
        "# #     # print(wcss)\n",
        "\n",
        "\n",
        "# # plt.plot(range(1,100), wcss)\n",
        "\n",
        "# plt.title('Elbow Method')\n",
        "# plt.xlabel('Number of Clusters')\n",
        "# plt.ylabel('WCSS')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sDSL6XNkWw-I"
      },
      "outputs": [],
      "source": [
        "def groupFeaturesByLabels(data,labels):\n",
        "  group={}\n",
        "  pou={}\n",
        "  for vec,label in zip(data,labels):\n",
        "    if(label not in group.keys()):\n",
        "      group[label]=[]\n",
        "    group[label].append(vec)\n",
        "    pou[f'{vec}']=label\n",
        "\n",
        "  return group,pou\n",
        "gro,pou=groupFeaturesByLabels(feat,labelsDB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jh1Mfw1lepvx"
      },
      "outputs": [],
      "source": [
        "def featureCount(labelsDB,vectors,pou):\n",
        "  count=1+np.amax(labelsDB)\n",
        "  imgFeat=[]\n",
        "  for image_vectors in vectors:\n",
        "    feat=np.zeros(count)\n",
        "    for vec in image_vectors:\n",
        "      g=pou[f'{vec}']\n",
        "      feat[g]=feat[g]+1\n",
        "    imgFeat.append(feat)\n",
        "  return np.array(imgFeat)\n",
        "\n",
        "featurecount=featureCount(labelsDB,vect,pou)\n",
        "featurecount"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_BsI09SXnd16"
      },
      "outputs": [],
      "source": [
        "####################################\n",
        "classify(featurecount,label_array )\n",
        "####################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5c1q2-Uxw8O"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score,f1_score,ConfusionMatrixDisplay\n",
        "\n",
        "def classifyAndshowMetrics(datapoints, labels):\n",
        "  test_size = 0.2\n",
        "  X_train, X_test, y_train, y_test = train_test_split(datapoints, labels, test_size=test_size, random_state=42)\n",
        "\n",
        "  clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "  clf.fit(X_train, y_train)\n",
        "\n",
        "  y_pred = clf.predict(X_test)\n",
        "\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  precision = precision_score(y_test, y_pred, average='macro')\n",
        "  recall =recall_score(y_test, y_pred, average='macro')\n",
        "  f1 =f1_score(y_test, y_pred, average='macro')\n",
        "\n",
        "  print(\"Precision:\", precision)\n",
        "  print(\"Recall:\", recall)\n",
        "  print(\"F1-score:\", f1)\n",
        "  print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "  cm=confusion_matrix(y_test, y_pred)\n",
        "  disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "  disp.plot()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5lt4sN6V3lls"
      },
      "outputs": [],
      "source": [
        "classifyAndshowMetrics(featurecount,label_array  )#true_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zWoFUaXDw7LT"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "\n",
        "correlation_matrix = np.corrcoef(feat, rowvar=False)\n",
        "sns.heatmap(correlation_matrix, annot=True)\n",
        "\n",
        "print(correlation_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VaNQEXd6P_5k"
      },
      "outputs": [],
      "source": [
        "# data = create(convertToHSV(images[123]))\n",
        "# kmeans = KMeans(n_clusters=4, n_init=10).fit(data['info'])\n",
        "# labels = kmeans.labels_\n",
        "# plt.subplot(2, 2, 1)\n",
        "# plt.imshow(np.array(images[123]).reshape((499, 499,3)))\n",
        "# plt.axis('off')\n",
        "# plt.subplot(2, 2, 2)\n",
        "# plt.scatter(data['x'], data['y'], c=labels, cmap='viridis')\n",
        "# plt.axis('off')\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2-DYjTK3V16"
      },
      "source": [
        "# Plot results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rcFP3Utm3KZR"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score,f1_score,ConfusionMatrixDisplay\n",
        "\n",
        "def classifyAndshow(datapoints, labels):\n",
        "  test_size = 0.2\n",
        "  X_train, X_test, y_train, y_test = train_test_split(datapoints, labels, test_size=test_size, random_state=42)\n",
        "\n",
        "  clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "  clf.fit(X_train, y_train)\n",
        "\n",
        "  y_pred = clf.predict(X_test)\n",
        "  s=[]\n",
        "  for a in X_test:\n",
        "    i=0;\n",
        "    for d in datapoints:\n",
        "      if(np.array_equal(a,d)):\n",
        "         s.append(i)\n",
        "         break\n",
        "      i=i+1\n",
        "  imgs=[my_array[i] for i in s]\n",
        "  labl=[label_array[i] for i in s]\n",
        "  m=0;\n",
        "  for i,j,z in zip(imgs,labl,y_pred):\n",
        "      plt.figure(m)\n",
        "      plt.imshow(np.array(i).reshape((499, 499,3)))\n",
        "      plt.title(f'label:{j},pred:{z}')\n",
        "      m=m+1\n",
        "\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yRgk4KQk8ft2"
      },
      "outputs": [],
      "source": [
        "classifyAndshow(featurecount,label_array)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}